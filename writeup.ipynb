{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Lane Finding Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "### Camera Calibration\n",
    "\n",
    "#### 1. Camera calibration using calibration images.\n",
    "\n",
    "The code for this step is contained in the 1-3 code cell of the IPython notebook.  \n",
    "\n",
    "I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.  \n",
    "\n",
    "I then used the output `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  I applied this distortion correction to the test image using the `cv2.undistort()` function and obtained this result: \n",
    "\n",
    "![alt text](images/dist_cal_1.png)\n",
    "\n",
    "### Pipeline (single images)\n",
    "\n",
    "#### 1. Undistort the image\n",
    "To demonstrate this step, I will describe how I apply the distortion correction to one of the test images like this one:\n",
    "![alt text](images/DistortVsUnDistort.png)\n",
    "\n",
    "#### 2. Threshold the image\n",
    "The thresholding functions are in code cell 4 and 5 of the jupyter notebook.  \n",
    "I used a combination of color and gradient thresholds to generate a binary image.  \n",
    "Below is an example of my output for this step. The first image is the original image. The second is the thresholded image.  \n",
    "In the third image, the blue color is the contribution from the color thresholding, while the green color is the contribution from the grayscale thresholding.\n",
    "\n",
    "![alt text](images/Undistorted1.png)\n",
    "![alt text](images/Undistorted_Threshold.png)\n",
    "\n",
    "#### 3. Perspective Transform\n",
    "The perspective transform function is in the code cell 15, the corner selection is in code cell 10 to 14 of the jupyter notebook.\n",
    "\n",
    "Corner selection on the sample images:\n",
    "![alt text](images/Corner1.png)\n",
    "![alt text](images/Corner2.png)\n",
    "\n",
    "Transformed image:\n",
    "![alt text](images/Transformed1.png)\n",
    "\n",
    "#### 4. Lane line detection\n",
    "The lane line detection functions are in code cell 19 and 20.\n",
    "The function in code cell 19 is using sliding window to find the lines.  \n",
    "The function in code cell 20 takes in a precalculated polynomial fit and try to detect line starting from the line from the ply fit.\n",
    "Example of the polynomial line fit superimposed on the warped image:  \n",
    "With sliding windows:\n",
    "![alt text](images/SlidingWindows.png)\n",
    "Without sliding windows:\n",
    "![alt text](images/NoSlidingWindows.png)\n",
    "\n",
    "#### 5. Curvature measurement\n",
    "The code for measuring curvature is in code cell 27.\n",
    "\n",
    "#### 6. Sample image with lane highlighted\n",
    "The code to draw line on the frame is in code cell 28-29.\n",
    "![alt text](images/LaneDetectedSampleImages.png)\n",
    "\n",
    "#### 7. Final Pipeline Step\n",
    "The code for pipeline function is in code cell 31, 32, 33.  \n",
    "\n",
    "1. Undistort, threshold and perspective transform the image\n",
    "2. If there is no history (or first frame), find lane line with sliding windows\n",
    "3. If there is existing poly fit, find lane line starting from the existing poly fit.\n",
    "3. Measure curvature\n",
    "4. Do Sanity Check:\n",
    "   - Check lane width (if width is out of range, reset)\n",
    "   - Check curvature (if either left or right curvature is less than 200m, reset).\n",
    "     There is no tight turn in the video, so it must be false detection.\n",
    "   - Check sign on the first term of the polynomial equation (if sign changes from - to + or vice versa, reset)\n",
    "     If there is sign change, meaning left turn change to right turn or vice versa, the existing polynomial fit\n",
    "     will not fit nicely.\n",
    "   Reset means go to #2\n",
    "5. Record polynomial fit and the x values of the line fit.\n",
    "   Keep history of 5 frames.\n",
    "6. Draw lane using the average fit from the last 5 frames to reduce jitter.\n",
    "\n",
    "\n",
    "### Pipeline (video)\n",
    "\n",
    "#### 1. Link to video\n",
    "\n",
    "Here's a [link to my video result](./project_video_out.mp4)\n",
    "\n",
    "\n",
    "### Discussion\n",
    "\n",
    "#### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?\n",
    "One of the most important step in this project is the thresholding of the image. The pipeline is likely to fail where the contrast between the line and the road are not good or covered by shadows, etc. For improvement, need to find a thresholding method that produce clear lines so that the lanes can be detected with more confidence.\n",
    "The sanity checks can be improved, although for this project they work pretty well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
